{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë²¡í„° DB ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# /home/wanted-1/potenup-workspace/Project/Final_Project/team2/Unreal_AI/apps/voice_quest/data/PDF/Epilouge(final).pdf\n",
    "loader = PyMuPDFLoader(\"./data/PDF/Epilouge(final).pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = text.replace(\"Document\", \"\")\n",
    "    return new_text\n",
    "\n",
    "for i in range(3):\n",
    "    docs[i].page_content = preprocess(docs[i].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "keyword: ë‹¬ë¹› ì—°ëª»\n",
      "---\n",
      "keyword: ë‹¬ë¹› ì—°ëª»\n",
      "---\n",
      "keyword: ì—°ìë°¥\n",
      "---\n",
      "keyword: ì—°ìë°¥\n",
      "---\n",
      "keyword: ì‚¶ì€ ë‹¹ê·¼\n",
      "---\n",
      "keyword: ê°œêµ¬ë¦¬ ë™ì‚°\n",
      "---\n",
      "keyword: ì—°ëª» íŒŒë¦¬\n",
      "---\n",
      "keyword: ì™•ì™•ë²Œ\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def split_with_bracket_keyword(documents):\n",
    "    result = []\n",
    "    pattern = r\"\\[(.*?)\\]\\n\"  # [í‚¤ì›Œë“œ] íŒ¨í„´\n",
    "\n",
    "    for doc in documents:\n",
    "        text = doc.page_content\n",
    "        matches = list(re.finditer(pattern, text))\n",
    "\n",
    "        for i, match in enumerate(matches):\n",
    "            keyword = match.group(1)\n",
    "            start = match.end()\n",
    "            end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "            chunk_text = text[start:end].strip()\n",
    "\n",
    "            if chunk_text:\n",
    "                result.append(\n",
    "                    Document(\n",
    "                        page_content=chunk_text,\n",
    "                        metadata={**doc.metadata, \"keyword\": keyword}\n",
    "                    )\n",
    "                )\n",
    "    return result\n",
    "\n",
    "# keyword ê¸°ì¤€ìœ¼ë¡œ ë¨¼ì € ìª¼ê°œê³ \n",
    "split_docs = split_with_bracket_keyword(docs)\n",
    "\n",
    "# ê·¸ ë‹¤ìŒì— chunk ë‚˜ëˆ„ê¸°\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\", \" \"]  # ì—¬ê¸°ì„  ### ì•ˆ ì¨ë„ ë¨, ìœ„ì—ì„œ ì´ë¯¸ ìª¼ê°¬\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(split_docs)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "for chunk in chunks:\n",
    "    print(\"---\")\n",
    "    print(f\"keyword: {chunk.metadata.get('keyword')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1013506/284930069.py:6: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vector_db.persist()\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "vector_db = Chroma.from_documents(documents=chunks, embedding=embedding, persist_directory=\"./data/chroma_db\", collection_name=\"openai\")\n",
    "vector_db.persist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í€´ì¦ˆ LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¬ë¹› ì—°ëª»\n"
     ]
    }
   ],
   "source": [
    "# í€´ì¦ˆ ì •ë‹µ ëœë¤ìœ¼ë¡œ ì„ íƒ\n",
    "import random\n",
    "\n",
    "answer_list = [\"ë‹¬ë¹› ì—°ëª»\", \"ì—°ìë°¥\", \"ì‚¶ì€ ë‹¹ê·¼\", \"ê°œêµ¬ë¦¬ ë™ì‚°\", \"ì—°ëª» íŒŒë¦¬\", \"ì™•ì™•ë²Œ\"]\n",
    "answer = random.choice(answer_list)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1013506/4192657665.py:22: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_db = Chroma(persist_directory=\"./data/chroma_db\", embedding_function=OpenAIEmbeddings(), collection_name=\"openai\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìš°ë¦¬ ì•„ê¸°ê°€ ì²˜ìŒìœ¼ë¡œ ë¬¼ì— ë°œ ë‹´ê¸€ ë•Œ, ì—°ëª» ìœ„ì— ë­ê°€ ì˜ˆì˜ê²Œ ë¹„ì³ì„œ ë°˜ì§ê±°ë ¸ë”ë¼?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "template = \"\"\"\n",
    "You are a mom.  \n",
    "Please follow the rules to create a natural and warm question for your child, based on the correct answer.\n",
    "\n",
    "Rules:  \n",
    "- Answer in Korean.  \n",
    "- The question must be only one sentence.  \n",
    "- Never directly mention the correct answer.  \n",
    "- Use emotional or visual cues from the context to help the child recall the memory naturally.  \n",
    "- Do not explain or give hints. Only create a question.  \n",
    "- Use casual and friendly Korean language.\n",
    "\n",
    "Answer: {answer}\n",
    "\n",
    "context: {context}\n",
    "\n",
    "question:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "vector_db = Chroma(persist_directory=\"./data/chroma_db\", embedding_function=OpenAIEmbeddings(), collection_name=\"openai\")\n",
    "\n",
    "retriever = vector_db.as_retriever(\n",
    "    search_type = \"mmr\",\n",
    "    search_kwargs = {\"k\" : 2, \"filter\" : {\"keyword\" : answer}}\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model= \"gemini-2.0-flash\", temperature=0.5)\n",
    "\n",
    "chain = (\n",
    "    {\"context\" : itemgetter(\"answer\") | retriever, \"answer\" : itemgetter(\"answer\")}\n",
    "    | prompt\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"answer\" : answer})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íŒíŠ¸ ìƒì„± LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.schema.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacode97\n",
      "ìš°ë¦¬ ê°œêµ¬ë½ì´ê°€ ë¨¹ì—ˆë˜ íŠ¹ë³„í•œ ìŒì‹ ê¸°ì–µë‚˜ë‹ˆ? \n",
      "ìŒ, ìì‚¬ê·€ì˜ í–¥ê¸‹í•¨ì´ ë°¥ì•Œ í•˜ë‚˜í•˜ë‚˜ì— ìŠ¤ë©°ë“¤ì–´ ìˆì—ˆì§€. ë§ˆì¹˜ ë„¤ ê±±ì •ì´ ìŠ¤ë¥´ë¥µ ë…¹ì•„ë‚´ë¦¬ëŠ” ê²ƒì²˜ëŸ¼ ë§ì´ì•¼. \n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "ë„ˆëŠ” ë‹¤ì •í•˜ê³  ë”°ëœ»í•œ ì—„ë§ˆì•¼. ì•„ì´ê°€ í€´ì¦ˆë¥¼ í’€ê³  ìˆëŠ”ë°, ì •ë‹µì„ ì§ì ‘ ì•Œë ¤ì£¼ë©´ ì•ˆ ë¼.  \n",
    "ì•„ì´ ìŠ¤ìŠ¤ë¡œ ê¸°ì–µí•´ë‚¼ ìˆ˜ ìˆë„ë¡ ê°ì„±ì ì´ê³  ë¹„ìœ ì ì¸ íŒíŠ¸ë¥¼ ì£¼ëŠ” ê²Œ ë„ˆì˜ ì—­í• ì´ì•¼.\n",
    "\n",
    "ê·œì¹™:\n",
    "- íŒíŠ¸ëŠ” 2~3ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±í•´ì•¼ í•´.\n",
    "- ì •ë‹µì„ ì§ì ‘ ì–¸ê¸‰í•˜ê±°ë‚˜, ê¸€ì ìˆ˜, ì² ì, ì´ˆì„±, ìœ„ì¹˜ ë“±ì„ ì•Œë ¤ì£¼ëŠ” ì‹ì˜ ë‹¨ì„œëŠ” ì£¼ì§€ ë§ˆ.\n",
    "- íŠ¹íˆ ì•„ë˜ ë‹¨ì–´ë“¤ì€ íŒíŠ¸ì—ì„œ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆ: [\"ì—°\", \"ì\", \"ë°¥\"]\n",
    "- ì•„ì´ê°€ ì§ˆë¬¸ì„ í•´ë„ í•­ìƒ íŒíŠ¸ë¡œë§Œ ë‹µí•´. ì–´ë–¤ ì§ˆë¬¸ì—ë„ ì •ë‹µì˜ ì§ì ‘ì ì¸ ì •ë³´ëŠ” ì£¼ì§€ ì•Šì•„.\n",
    "- ì•„ì´ê°€ ì˜¤ë‹µì„ ë§í•˜ë©´ \"ê·¸ê±´ ì•„ë‹ˆì•¼~\"ì²˜ëŸ¼ ë¶€ë“œëŸ½ê²Œ ë°˜ì‘í•˜ê³ , ì´ì–´ì„œ íŒíŠ¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¤˜.\n",
    "- ë§íˆ¬ëŠ” ì¼ìƒì ì¸ ì—„ë§ˆ ë§íˆ¬ë¡œ, ë„ˆë¬´ ë¬¸ì–´ì²´ì²˜ëŸ¼ ë”±ë”±í•˜ê²Œ ë§í•˜ì§€ ì•Šì•„.\n",
    "\n",
    "ì…ë ¥:\n",
    "- ì•„ì´ì˜ ë‹µë³€: {user_word}\n",
    "- ì •ë‹µ: {answer}\n",
    "- ëŒ€í™” ê¸°ë¡: {chat_history}\n",
    "- ì°¸ê³  ë¬¸ë§¥: {context}\n",
    "\n",
    "ì¶œë ¥:\n",
    "- ì—„ë§ˆì˜ íŒíŠ¸:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "vector_db = Chroma(persist_directory=\"./data/chroma_db\", embedding_function=OpenAIEmbeddings(), collection_name=\"openai\")\n",
    "\n",
    "retriever = vector_db.as_retriever(\n",
    "    search_type = \"mmr\",\n",
    "    search_kwargs = {\"k\" : 2, \"filter\" : {\"keyword\" : answer}}\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model= \"gemini-2.0-flash\", temperature=0.5)\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": lambda x: retriever.invoke(x[\"user_word\"].content),\n",
    "        \"user_word\": itemgetter(\"user_word\"),   \n",
    "        \"answer\": itemgetter(\"answer\"),\n",
    "        \"chat_history\": itemgetter(\"chat_history\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "history_store = {}  # ì„¸ì…˜ ê¸°ë¡ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "\n",
    "# ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    print(session_id)\n",
    "    if session_id not in history_store:  # ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš°\n",
    "        # ìƒˆë¡œìš´ ChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ storeì— ì €ì¥\n",
    "        history_store[session_id] = ChatMessageHistory()\n",
    "    return history_store[session_id]  # í•´ë‹¹ ì„¸ì…˜ IDì— ëŒ€í•œ ì„¸ì…˜ ê¸°ë¡ ë°˜í™˜\n",
    "\n",
    "history_chain = RunnableWithMessageHistory(  # RunnableWithMessageHistory ê°ì²´ ìƒì„±\n",
    "            chain,  # ì‹¤í–‰í•  Runnable ê°ì²´\n",
    "            get_session_history,  # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "            input_messages_key=\"user_word\",  # ì…ë ¥ ë©”ì‹œì§€ì˜ í‚¤\n",
    "            history_messages_key=\"chat_history\",  # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤\n",
    "        )\n",
    "response = history_chain.invoke(\n",
    "    {\n",
    "        \"user_word\": HumanMessage(content=\"ì •ë‹µì´ ëª‡ ê¸€ìì•¼?\"),  # â† ì—¬ê¸°ë¥¼ HumanMessageë¡œ!\n",
    "        \"answer\": answer\n",
    "    },\n",
    "    config={\"configurable\": {\"session_id\": \"Jacode97\"}}\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacode97\n",
      "ì•„ì´ê³ , ê¶ê¸ˆí–ˆìª„? \n",
      "ìŒ... ê°œêµ¬ë½ì´ê°€ ì—°ëª»ì—ì„œ ì²˜ìŒ ë§›ë³¸ íŠ¹ë³„í•œ ìŒì‹ ìˆì–ì•„. ë„“ê³  í‘¸ë¥¸ ìì— ì‹¸ì—¬ì„œ í–¥ê¸‹í•¨ì´ ê°€ë“í–ˆë˜ ê·¸ ë°¥ ë§ì´ì•¼. ë§ˆì¹˜ ë„¤ê°€ ì¢‹ì•„í•˜ëŠ” ê½ƒì²˜ëŸ¼ ê·€í•œ ì¬ë£Œë“¤ì´ ë°¥ ì†ì— ìˆ¨ì–´ ìˆì—ˆì§€.\n"
     ]
    }
   ],
   "source": [
    "response = history_chain.invoke(\n",
    "    {\n",
    "        \"user_word\": HumanMessage(content=\"ì •ë‹µì´ ëª‡ê¸€ìëƒê³ \"),  # â† ì—¬ê¸°ë¥¼ HumanMessageë¡œ!\n",
    "        \"answer\": answer\n",
    "    },\n",
    "    config={\"configurable\": {\"session_id\": \"Jacode97\"}}\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìŒì„± ë°ì´í„° base64 ë³µì›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë…¹ìŒ ì‹œì‘...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/audio/output.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     write(filename, samplerate, recording)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124më…¹ìŒ ì™„ë£Œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mrecord_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36mrecord_wav\u001b[0;34m(filename, duration, samplerate)\u001b[0m\n\u001b[1;32m      6\u001b[0m recording \u001b[38;5;241m=\u001b[39m sd\u001b[38;5;241m.\u001b[39mrec(\u001b[38;5;28mint\u001b[39m(duration \u001b[38;5;241m*\u001b[39m samplerate), samplerate\u001b[38;5;241m=\u001b[39msamplerate, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m sd\u001b[38;5;241m.\u001b[39mwait()  \u001b[38;5;66;03m# ë…¹ìŒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecording\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124më…¹ìŒ ì™„ë£Œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/io/wavfile.py:793\u001b[0m, in \u001b[0;36mwrite\u001b[0;34m(filename, rate, data)\u001b[0m\n\u001b[1;32m    791\u001b[0m     fid \u001b[38;5;241m=\u001b[39m filename\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 793\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m fs \u001b[38;5;241m=\u001b[39m rate\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/audio/output.wav'"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def record_wav(filename=\"./data/audio/output.wav\", duration=5, samplerate=44100):\n",
    "    print(\"ë…¹ìŒ ì‹œì‘...\")\n",
    "    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')\n",
    "    sd.wait()  # ë…¹ìŒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°\n",
    "    write(filename, samplerate, recording)\n",
    "    print(f\"ë…¹ìŒ ì™„ë£Œ: {filename}\")\n",
    "\n",
    "record_wav()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UklGRsy6BgBXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0Yai6BgAAAAAA//8AAAAAAAAAAP//AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP//AAAAAAAAAAAAAAAAAAAAAAAAAQAAAP//AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD//wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAQABAAAAAAAAAP//AQABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAABAAAAAAAAAAAAAAD//wAAAAAAAAAAAAAAAAAAAAAAAAAA////////AAAAAAAAAAD//wAAAAAAAAAAAAAAAAAAAAAAAAEAAAABAAAAAAAAAAAAAAAAAAEA//8AAAEA//8AAAAAAAAAAAAAAAAAAP//AAAAAAAA//8AAP//AAAAAAAAAAAAAP//AAAAAAAAAAAAAAAA//8AAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAABAAAAAAAAAAAAAAD//wAAAAAAAAAAAAAAAAAAAAAAAAEAAAABAAAAAAABAP//AQAAAAAAAAD/////AAAAAAAA//8AAP//AAAAAAAA//8AAAAAAAAAAAEAAAAAAAAAAAAAAAAAAQAAAAEAAAAAAAAAAAAAAAAAAQAAAAAAAAABAAEAAAAAAAAAAAAAAAAAAAAAAP//AQAAAAAAAAAAAAAAAAAAAAEAAAAAAP//AAAAAAAA/////wAAAAABAAAA//8AAAAAAAAAAAAAAAD/////AAAAAP//AQAAAAEAAAAAAAAAAAAAAAAAAQAAAAAAAAD//wAAAAAAAAAAAAABAP//AAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAD//wAAAAD//wAAAAD//wAAAAAAAAAAAAAAAAAAAAABAAAAAAD//wEAAAAAAP////8AAAAAAAABAP//\n",
      "575\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±í•˜ê¸°\n",
    "import base64\n",
    "\n",
    "def wav_to_base64(wav_path: str) -> str:\n",
    "    \"\"\"WAV íŒŒì¼ì„ base64 ë¬¸ìì—´ë¡œ ë³€í™˜\"\"\"\n",
    "    with open(wav_path, \"rb\") as wav_file:\n",
    "        wav_bytes = wav_file.read()\n",
    "    base64_str = base64.b64encode(wav_bytes).decode(\"utf-8\")\n",
    "    return base64_str\n",
    "\n",
    "def split_base64_chunks(base64_data, chunk_size):\n",
    "    total_size = len(base64_data)\n",
    "    chunks = [base64_data[i:i+chunk_size] for i in range(0, total_size, chunk_size)]\n",
    "    return total_size, len(chunks), chunks\n",
    "\n",
    "wav_path = \"./data/audio/output.wav\"\n",
    "chunk_size = 1024  # ì²­í¬ í¬ê¸° ì¡°ì ˆ ê°€ëŠ¥\n",
    "\n",
    "# base64 ë¬¸ìì—´ ë³€í™˜\n",
    "base64_audio = wav_to_base64(wav_path)\n",
    "\n",
    "# base64ë¥¼ ì²­í¬ ë‚˜ëˆ„ê¸°\n",
    "total_size, num_chunks, chunks = split_base64_chunks(base64_audio, chunk_size)\n",
    "print(chunks[0])\n",
    "print(num_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffers = {}  \n",
    "total_sizes = {}  \n",
    "chunk_sizes = {} \n",
    "\n",
    "def init_buffer(quiz_id, total_size, chunk_size):\n",
    "    buffers[quiz_id] = {}\n",
    "    total_sizes[quiz_id] = total_size\n",
    "    chunk_sizes[quiz_id] = chunk_size\n",
    "\n",
    "def receive_packet(quiz_id, start, index, fin, total_size, chunk_size, raw_data):\n",
    "    \"\"\"íŒ¨í‚· ë°›ìœ¼ë©´ì„œ ë³µì› ì‹œë„\"\"\"\n",
    "    global buffers, total_sizes, chunk_sizes\n",
    "\n",
    "    if start == 1:\n",
    "        print(f\"[{quiz_id}] ìƒˆ ì „ì†¡ ì‹œì‘. ì´ˆê¸°í™”.\")\n",
    "        init_buffer(quiz_id, total_size, chunk_size)\n",
    "\n",
    "    buffers[quiz_id][index] = raw_data\n",
    "\n",
    "    if fin == 1:\n",
    "        print(f\"[{quiz_id}] ë§ˆì§€ë§‰ íŒ¨í‚· ë°›ìŒ. ë³µì› ì‹œì‘.\")\n",
    "        chunks = buffers[quiz_id]\n",
    "        sorted_data = b''.join(chunks[i] for i in sorted(chunks.keys()))\n",
    "        # ë²„í¼ ì •ë¦¬\n",
    "        del buffers[quiz_id]\n",
    "        del total_sizes[quiz_id]\n",
    "        del chunk_sizes[quiz_id]\n",
    "        return sorted_data\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data = None\n",
    "quiz_id = \"ì¬ì‹ìŠ¤ í€´ì¦ˆ\"\n",
    "\n",
    "for index, chunk in enumerate(chunks):\n",
    "    start = 1 if index == 0 else 0\n",
    "    fin = 1 if index == num_chunks - 1 else 0\n",
    "    reconstructed_data = receive_packet(\n",
    "        quiz_id=quiz_id,\n",
    "        start=start,\n",
    "        index=index,\n",
    "        fin=fin,\n",
    "        total_size=total_size,\n",
    "        chunk_size=chunk_size,\n",
    "        raw_data=chunk.encode(\"utf-8\")  # ë¬¸ìì—´ â†’ bytes (ì—¬ê¸°ê°€ ì¤‘ìš”!)\n",
    "    )\n",
    "    if reconstructed_data:\n",
    "        print(f\"ë³µì› ì„±ê³µë„~! ë³µì›ëœ í¬ê¸°: {len(reconstructed_data)} bytes\")\n",
    "\n",
    "reconstructed_str = reconstructed_data.decode(\"utf-8\")\n",
    "decoded_bytes = base64.b64decode(reconstructed_str)\n",
    "with open(\"./data/wav/restore.wav\", \"wb\") as f:\n",
    "    f.write(decoded_bytes)\n",
    "assert reconstructed_str == base64_audio, \"ë§í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ì›ë³¸ê³¼ ë‹¬ë¼ìš©~!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STT(Speech To Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import soundfile as sf \n",
    "import whisper\n",
    "import librosa \n",
    "\n",
    "#Whisper ëª¨ë¸ ë¡œë“œ\n",
    "model = whisper.load_model(\"medium\")  # tiny, base, small, medium, large ì¤‘ ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒ˜í”Œë ˆì´íŠ¸: 44100, ì˜¤ë””ì˜¤ ê¸¸ì´: 220500\n",
      " ê°œêµ¬ë¦¬ ìŒˆë°•\n"
     ]
    }
   ],
   "source": [
    "# base64 ë¬¸ìì—´ â†’ ë°”ì´ë„ˆë¦¬ ë””ì½”ë“œ\n",
    "decoded_wav_bytes = base64.b64decode(reconstructed_data)\n",
    "\n",
    "# BytesIOë¡œ ê°ì‹¸ì„œ ì½ê¸°\n",
    "audio_bytes = io.BytesIO(decoded_wav_bytes)\n",
    "\n",
    "# WAV â†’ numpy array\n",
    "audio_data, samplerate = sf.read(audio_bytes, dtype='float32')\n",
    "\n",
    "print(f\"ìƒ˜í”Œë ˆì´íŠ¸: {samplerate}, ì˜¤ë””ì˜¤ ê¸¸ì´: {len(audio_data)}\")\n",
    "\n",
    "# Whisperê°€ 16kHzë¥¼ ìš”êµ¬í•˜ë‹ˆê¹Œ í•„ìš”í•˜ë©´ ë¦¬ìƒ˜í”Œë§\n",
    "if samplerate != 16000:\n",
    "    audio_data = librosa.resample(audio_data, orig_sr=samplerate, target_sr=16000)\n",
    "    samplerate = 16000\n",
    "\n",
    "# STT ìˆ˜í–‰\n",
    "result = model.transcribe(audio_data, fp16=False, language='ko')\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë“ˆí™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavReconstructor:\n",
    "    '''ìª¼ê°œì§„ wavíŒŒì¼ ë³µì› í´ë˜ìŠ¤'''\n",
    "    def __init__(self):\n",
    "        self.buffers = {}\n",
    "        self.total_sizes = {}\n",
    "        self.chunk_sizes = {}\n",
    "\n",
    "    def init_buffer(self, quiz_id, total_size, chunk_size):\n",
    "        '''ìƒˆ ì „ì†¡ ì‹œì‘ ì‹œ í•´ë‹¹ quiz_idì˜ ë²„í¼ ì´ˆê¸°í™”'''\n",
    "        self.buffers[quiz_id] = {}\n",
    "        self.total_sizes[quiz_id] = total_size\n",
    "        self.chunk_sizes[quiz_id] = chunk_size\n",
    "\n",
    "    def receive_packet(self, quiz_id, start, index, fin, total_size, chunk_size, raw_data):\n",
    "        '''\n",
    "        startê°€ 1ì¼ë•Œ ì „ì†¡ ì‹œì‘ ë° ë²„í¼ ì´ˆê¸°í™”,\n",
    "        finì´ 1ì¼ë•Œ íŒ¨í‚· join í›„ return \n",
    "        '''\n",
    "        if start == 1:\n",
    "            # print(f\"[{quiz_id}] ìƒˆ ì „ì†¡ ì‹œì‘. ì´ˆê¸°í™”.\")\n",
    "            self.init_buffer(quiz_id, total_size, chunk_size)\n",
    "\n",
    "        self.buffers[quiz_id][index] = raw_data\n",
    "\n",
    "        if fin == 1:\n",
    "            # print(f\"[{quiz_id}] ë§ˆì§€ë§‰ íŒ¨í‚· ë°›ìŒ. ë³µì› ì‹œì‘.\")\n",
    "            chunks = self.buffers[quiz_id]\n",
    "            sorted_data = b''.join(chunks[i] for i in sorted(chunks.keys()))\n",
    "            # ë²„í¼ ì •ë¦¬\n",
    "            del self.buffers[quiz_id]\n",
    "            del self.total_sizes[quiz_id]\n",
    "            del self.chunk_sizes[quiz_id]\n",
    "            return sorted_data\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³µì› ì„±ê³µë„~! ë³µì›ëœ í¬ê¸°: 588060 bytes\n"
     ]
    }
   ],
   "source": [
    "sock = WavReconstructor()\n",
    "# print(total_size, num_chunks, chunks)\n",
    "for index, chunk in enumerate(chunks):\n",
    "    start = 1 if index == 0 else 0\n",
    "    fin = 1 if index == num_chunks - 1 else 0\n",
    "    reconstructed_data = sock.receive_packet(\n",
    "        quiz_id=quiz_id,\n",
    "        start=start,\n",
    "        index=index,\n",
    "        fin=fin,\n",
    "        total_size=total_size,\n",
    "        chunk_size=chunk_size,\n",
    "        raw_data=chunk.encode(\"utf-8\") \n",
    "    )\n",
    "    if reconstructed_data:\n",
    "        print(f\"ë³µì› ì„±ê³µë„~! ë³µì›ëœ í¬ê¸°: {len(reconstructed_data)} bytes\")\n",
    "\n",
    "##########SAVE POINT###############\n",
    "reconstructed_str = reconstructed_data.decode(\"utf-8\")\n",
    "decoded_bytes = base64.b64decode(reconstructed_str)\n",
    "with open(\"./data/audio/output.wav\", \"wb\") as f:\n",
    "    f.write(decoded_bytes)\n",
    "assert reconstructed_str == base64_audio, \"ë§í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ì›ë³¸ê³¼ ë‹¬ë¼ìš©~!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STTEngine:\n",
    "    '''Speech to Text í´ë˜ìŠ¤(Whisperëª¨ë¸ ì‚¬ìš©)'''\n",
    "    def __init__(self):\n",
    "        self.model = whisper.load_model(\"medium\")\n",
    "    \n",
    "    def base_to_np(self, base64_str):\n",
    "        '''base64ë¥¼ numpyë¡œ ë³€í™˜í•˜ëŠ” ë©”ì„œë“œ'''\n",
    "        wav_bytes = base64.b64decode(base64_str)\n",
    "        audio_bytes = io.BytesIO(wav_bytes)\n",
    "        audio, samplerate = sf.read(audio_bytes, dtype=\"float32\")\n",
    "        if samplerate != 16000:\n",
    "            # print(f\"ìƒ˜í”Œë ˆì´íŠ¸ê°€ 16,000Hzê°€ ì•„ë‹™ë‹ˆë‹¤!, ìƒ˜í”Œ{samplerate}Hz, ì˜¤ë””ì˜¤{len(audio)}\")\n",
    "            audio = librosa.resample(audio, orig_sr=samplerate, target_sr=16000)\n",
    "            samplerate = 16000\n",
    "            # print(f\"ë¦¬ìƒ˜í”Œ í›„ {samplerate}Hzë¡œ ë¦¬ìƒ˜í”Œ\")\n",
    "        return audio\n",
    "    \n",
    "    def stt(self, base64_str):\n",
    "        result = self.model.transcribe(self.base_to_np(base64_str), fp16=False, language=\"ko\")\n",
    "        # print(f\"[STT Text] {result['text']}\")\n",
    "\n",
    "        return result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "stt = STTEngine()\n",
    "user_word = stt.stt(reconstructed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.schema.messages import HumanMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestLLM:\n",
    "    def __init__(self, prompt_path, db_params, answer):\n",
    "        self.llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.5)\n",
    "        self.prompt_path = prompt_path\n",
    "        self.answer = answer\n",
    "        self.vector_db = Chroma(**db_params)\n",
    "        self.prompt = self._set_prompt()\n",
    "        self.retriever = self._make_retriever()\n",
    "\n",
    "    def _make_retriever(self):\n",
    "        retriever = self.vector_db.as_retriever(\n",
    "            search_type=\"mmr\",\n",
    "            search_kwargs={\"k\": 2, \"filter\": {\"keyword\": self.answer}}\n",
    "        )\n",
    "        return retriever\n",
    "\n",
    "    def _get_template(self):\n",
    "        with open(self.prompt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "\n",
    "    def _set_prompt(self):\n",
    "        return ChatPromptTemplate.from_template(self._get_template())\n",
    "\n",
    "    def _make_chain(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Quiz(QuestLLM):\n",
    "    '''íŠ¸ë¦¬ê±° ì‹œì‘í•˜ë©´ í€´ì¦ˆë¥¼ ë‚´ëŠ” LLM'''\n",
    "    def __init__(self, prompt_path, db_params, answer):\n",
    "        super().__init__(prompt_path, db_params, answer)\n",
    "        self.chain = self._make_chain()\n",
    "\n",
    "    def _make_chain(self):\n",
    "        chain = (\n",
    "            {\n",
    "                \"context\": itemgetter(\"answer\") | self.retriever,\n",
    "                \"answer\": itemgetter(\"answer\"),\n",
    "            }\n",
    "            | self.prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        return chain\n",
    "\n",
    "    def start_quiz(self):\n",
    "        return self.chain.invoke({\"answer\": self.answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìš°ë¦¬ ê°œêµ¬ë½ì´, ì—„ë§ˆë‘ ì—°ëª»ê°€ì—ì„œ ìì‚¬ê·€ì— ì‹¸ì„œ ë¨¹ì—ˆë˜ ë°¥, ë¬´ìŠ¨ í–¥ì´ ë‚¬ì—ˆëŠ”ì§€ ê¸°ì–µë‚˜?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = \"ì—°ìë°¥\"\n",
    "db_params = {\n",
    "    \"persist_directory\": \"./data/chroma_ver2\",\n",
    "    \"embedding_function\" : OpenAIEmbeddings(),\n",
    "    \"collection_name\": \"openai\"\n",
    "}\n",
    "prompt_path = \"./prompts/quiz.prompt\"\n",
    "quiz = Quiz(prompt_path,db_params, answer)\n",
    "quiz.start_quiz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field \n",
    "\n",
    "class AnswerEvaluation(BaseModel):\n",
    "    is_answer : bool = Field(..., description=\"Please tell me if it is correct(True/False).\")\n",
    "    hint : str = Field(\"\", description=\"Generate a hint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class Hint(QuestLLM):\n",
    "    def __init__(self, prompt_path, db_params, answer):\n",
    "        super().__init__(prompt_path, db_params, answer)\n",
    "        self.history_store = {}\n",
    "        self.chain = self._make_chain()\n",
    "\n",
    "    def get_session_history(self, session_id):\n",
    "        if session_id not in self.history_store:\n",
    "            self.history_store[session_id] = ChatMessageHistory()\n",
    "        return self.history_store[session_id]\n",
    "\n",
    "    def _make_chain(self):\n",
    "        chain = (\n",
    "            {\n",
    "                \"context\": lambda x: self.retriever.invoke(x[\"user_word\"].content),\n",
    "                \"user_word\": itemgetter(\"user_word\"),   \n",
    "                \"answer\": itemgetter(\"answer\"),\n",
    "                \"chat_history\": itemgetter(\"chat_history\"),\n",
    "            }\n",
    "            | self.prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        return RunnableWithMessageHistory(\n",
    "            chain,\n",
    "            self.get_session_history,\n",
    "            input_messages_key=\"user_word\",\n",
    "            history_messages_key=\"chat_history\",\n",
    "        )\n",
    "\n",
    "    def similarity(self, user_word):\n",
    "        \"\"\"user_wordì™€ self.answerì˜ ìœ ì‚¬ë„(float)ë§Œ ë¦¬í„´\"\"\"\n",
    "        embedding_model = OpenAIEmbeddings()\n",
    "        user_vec = np.array(embedding_model.embed_query(user_word))\n",
    "        answer_vec = np.array(embedding_model.embed_query(self.answer))\n",
    "\n",
    "        similarity = np.dot(user_vec, answer_vec) / (np.linalg.norm(user_vec) * np.linalg.norm(answer_vec))\n",
    "        return similarity\n",
    "    \n",
    "    def contain_word(self,user_word):\n",
    "        contain = self.answer in user_word\n",
    "        return contain\n",
    "    \n",
    "    def invoke(self, user_word, session_id=\"default\"):\n",
    "        response = self.chain.invoke(\n",
    "            {\n",
    "                \"user_word\": HumanMessage(content=user_word),\n",
    "                \"answer\": self.answer\n",
    "            },\n",
    "            config={\"configurable\": {\"session_id\": session_id}}\n",
    "        )\n",
    "        # print(f\"[íŒíŠ¸] : {response}\")\n",
    "        similarity = self.similarity(user_word)\n",
    "        contain = self.contain_word(user_word)\n",
    "        return {\n",
    "            \"contain\": contain,\n",
    "            \"response\" : response,\n",
    "            \"similarity\" : similarity\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[íŒíŠ¸] : ì•„ì´ê³ , ìš°ë¦¬ ì•„ê°€ í‹€ë ¸ë„¤. ğŸ˜“ ìŒ... ì—„ë§ˆê°€ ë§‘ì€ ì—°ëª»ì—ì„œ í‘¸ë¥´ê³  ì»¤ë‹¤ë€ ììœ¼ë¡œ ì •ì„±ìŠ¤ëŸ½ê²Œ ì‹¸ì„œ ì§€ì–´ì¤¬ë˜ ë°¥ ê¸°ì–µë‚˜? ì£ì´ë‘ ì€í–‰ë„ ë„£ê³  ë§ì´ì•¼. ğŸ˜Œ\n"
     ]
    }
   ],
   "source": [
    "prompt_path = \"./prompts/hint.prompt\"\n",
    "hint = Hint(prompt_path, db_params, answer)\n",
    "response = hint.invoke(\"ê°œêµ¬ë¦¬ ìŒˆë°¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError(\"Expected str, BaseMessage, list[BaseMessage], or tuple[BaseMessage]. Got is_answer=False hint='ì•„ì´ê³ , ì•„ì‰½ë‹¤! ìŒ... ê°œêµ¬ë½ì´ê°€ ë°¥ì„ ë¨¹ìœ¼ë©´ì„œ ì—°ëª»ì„ ë°”ë¼ë´¤ì–ì•„. ê·¸ë•Œ ì—°ëª» ìœ„ì— ë­ê°€ ì”ì”íˆ ë–  ìˆì—ˆë”ë¼? ê·¸ë¦¬ê³  ì—„ë§ˆê°€ ê·¸ ìì— ë°¥ì„ ê³±ê²Œ ì‹¸ì¤¬ì—ˆì§€.'.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'is_answer': False,\n",
       " 'hint': 'ì•„ì´ê³ , ì•„ì‰½ë‹¤! ìŒ... ê°œêµ¬ë½ì´ê°€ ë°¥ì„ ë¨¹ìœ¼ë©´ì„œ ì—°ëª»ì„ ë°”ë¼ë´¤ì–ì•„. ê·¸ë•Œ ì—°ëª» ìœ„ì— ë­ê°€ ì”ì”íˆ ë–  ìˆì—ˆë”ë¼? ê·¸ë¦¬ê³  ì—„ë§ˆê°€ ê·¸ ìì— ë°¥ì„ ê³±ê²Œ ì‹¸ì¤¬ì—ˆì§€.',\n",
       " 'similarity': np.float64(0.9328349416930161)}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hint.invoke(\"ì—°ìë°¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_processing(text):\n",
    "    new_text = re.sub(r\"[^ê°€-í£a-zA-Z0-9\\s.,!?]\", \"\", text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tts(text,index):\n",
    "    from google.cloud import texttospeech\n",
    "\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "    input_text = texttospeech.SynthesisInput(text=text)\n",
    "\n",
    "    # Note: the voice can also be specified by name.\n",
    "    # Names of voices can be retrieved with client.list_voices().\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"ko-KR\",\n",
    "        name=\"ko-KR-Standard-B\",\n",
    "    )\n",
    "\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "\n",
    "    response = client.synthesize_speech(\n",
    "        input=input_text,\n",
    "        voice=voice,\n",
    "        audio_config=audio_config,\n",
    "    )\n",
    "\n",
    "    # The response's audio_content is binary.\n",
    "    with open(f\"./data/audio/output_{index}.mp3\", \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "        print('Audio content written to file \"output.mp3\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    \"persist_directory\": \"./data/chroma_db\",\n",
    "    \"embedding_function\" : OpenAIEmbeddings(),\n",
    "    \"collection_name\": \"openai\"\n",
    "}\n",
    "stt = STTEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì •ë‹µ] ì—°ìë°¥\n",
      "[ì—„ë§ˆ(í€´ì¦ˆ)] : ìŒ~ ê·¸ë•Œ ì—°ëª»ê°€ì—ì„œ ì—„ë§ˆê°€ ììœ¼ë¡œ ì˜ˆì˜ê²Œ ì‹¸ì¤¬ë˜ ë°¥, ë¬´ìŠ¨ í–¥ì´ ë‚¬ì—ˆì§€?\n",
      "Audio content written to file \"output.mp3\"\n",
      "[ê°œêµ¬ë¦¬] :  ê°œêµ¬ë¦¬ ìŒˆë°•\n",
      "[íŒíŠ¸] : ì•„ì´ê³ , ë•¡ì€ ì•„ë‹ˆì•¼~ ì—„ë§ˆê°€ ì •ì„±ìŠ¤ëŸ½ê²Œ ì‹¸ì¤¬ë˜ ë°¥ ê¸°ì–µë‚˜ë‹ˆ? í–¥ê¸‹í•œ ìì— ì‹¸ì—¬ì„œ ì€ì€í•œ í–¥ì´ ë‚¬ì—ˆì–ì•„. \n",
      "[ì—„ë§ˆ(íŒíŠ¸)] : ì•„ì´ê³ , ë•¡ì€ ì•„ë‹ˆì•¼~ ì—„ë§ˆê°€ ì •ì„±ìŠ¤ëŸ½ê²Œ ì‹¸ì¤¬ë˜ ë°¥ ê¸°ì–µë‚˜ë‹ˆ? í–¥ê¸‹í•œ ìì— ì‹¸ì—¬ì„œ ì€ì€í•œ í–¥ì´ ë‚¬ì—ˆì–ì•„. \n",
      "ìœ ì‚¬ë„ : 0.8312653295074122, ê¸€ììˆ˜ : ì•„\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "answer_list = [\"ë‹¬ë¹› ì—°ëª»\", \"ì—°ìë°¥\", \"ì·¨ë‹¹ê·¼\", \"ê°œë¥¼ë¦¬ë„ë¡œ ê²Œë¥¼ë„ë¼ ì‚°\", \"ë§ì™•ëŒ€ë²Œ\", \"ê¹íŒŒë¦¬\"]\n",
    "answer = random.choice(answer_list)\n",
    "print(f\"[ì •ë‹µ] {answer}\")\n",
    "\n",
    "# 1. í€´ì¦ˆ ìƒì„±\n",
    "quiz = Quiz(\n",
    "    prompt_path=\"./prompts/quiz.prompt\",\n",
    "    db_params=db_params,\n",
    "    answer = answer\n",
    ")\n",
    "print(f\"[ì—„ë§ˆ(í€´ì¦ˆ)] : {quiz.start_quiz()}\")\n",
    "\n",
    "# 2. ì‚¬ìš©ì ë‹µë³€ ì „ì²˜ë¦¬\n",
    "\n",
    "sock = WavReconstructor()\n",
    "# print(total_size, num_chunks, chunks)\n",
    "for index, chunk in enumerate(chunks):\n",
    "    start = 1 if index == 0 else 0\n",
    "    fin = 1 if index == num_chunks - 1 else 0\n",
    "    reconstructed_data = sock.receive_packet(\n",
    "        quiz_id=quiz_id,\n",
    "        start=start,\n",
    "        index=index,\n",
    "        fin=fin,\n",
    "        total_size=total_size,\n",
    "        chunk_size=chunk_size,\n",
    "        raw_data=chunk.encode(\"utf-8\") \n",
    "    )\n",
    "\n",
    "# 3. STT ë³€í™˜\n",
    "user_word = stt.stt(reconstructed_data)\n",
    "\n",
    "# 4. íŒíŠ¸ ìƒì„±\n",
    "hint = Hint(\n",
    "    prompt_path=\"./prompts/hint.prompt\",\n",
    "    db_params=db_params,\n",
    "    answer = answer\n",
    ")\n",
    "# 5. TTS ë³€í™˜\n",
    "result = text_processing(response['response'])\n",
    "tts(result,1)\n",
    "\n",
    "print(f\"[ê°œêµ¬ë¦¬] : {user_word}\")\n",
    "response = hint.invoke(user_word)\n",
    "print(f\"[ì—„ë§ˆ(íŒíŠ¸)] : {response['response']}\")\n",
    "print(f\"ìœ ì‚¬ë„ : {response['similarity']}, ê¸€ììˆ˜ : {response['response'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frog-stt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
