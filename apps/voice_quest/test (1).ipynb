{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 DB 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# /home/wanted-1/potenup-workspace/Project/Final_Project/team2/Unreal_AI/apps/voice_quest/data/PDF/Epilouge(final).pdf\n",
    "loader = PyMuPDFLoader(\"./data/PDF/Epilouge(final).pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = text.replace(\"Document\", \"\")\n",
    "    return new_text\n",
    "\n",
    "for i in range(3):\n",
    "    docs[i].page_content = preprocess(docs[i].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "keyword: 달빛 연못\n",
      "---\n",
      "keyword: 달빛 연못\n",
      "---\n",
      "keyword: 연잎밥\n",
      "---\n",
      "keyword: 연잎밥\n",
      "---\n",
      "keyword: 삶은 당근\n",
      "---\n",
      "keyword: 개구리 동산\n",
      "---\n",
      "keyword: 연못 파리\n",
      "---\n",
      "keyword: 왕왕벌\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def split_with_bracket_keyword(documents):\n",
    "    result = []\n",
    "    pattern = r\"\\[(.*?)\\]\\n\"  # [키워드] 패턴\n",
    "\n",
    "    for doc in documents:\n",
    "        text = doc.page_content\n",
    "        matches = list(re.finditer(pattern, text))\n",
    "\n",
    "        for i, match in enumerate(matches):\n",
    "            keyword = match.group(1)\n",
    "            start = match.end()\n",
    "            end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "            chunk_text = text[start:end].strip()\n",
    "\n",
    "            if chunk_text:\n",
    "                result.append(\n",
    "                    Document(\n",
    "                        page_content=chunk_text,\n",
    "                        metadata={**doc.metadata, \"keyword\": keyword}\n",
    "                    )\n",
    "                )\n",
    "    return result\n",
    "\n",
    "# keyword 기준으로 먼저 쪼개고\n",
    "split_docs = split_with_bracket_keyword(docs)\n",
    "\n",
    "# 그 다음에 chunk 나누기\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\", \" \"]  # 여기선 ### 안 써도 됨, 위에서 이미 쪼갬\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(split_docs)\n",
    "\n",
    "# 결과 확인\n",
    "for chunk in chunks:\n",
    "    print(\"---\")\n",
    "    print(f\"keyword: {chunk.metadata.get('keyword')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1013506/284930069.py:6: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vector_db.persist()\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "vector_db = Chroma.from_documents(documents=chunks, embedding=embedding, persist_directory=\"./data/chroma_db\", collection_name=\"openai\")\n",
    "vector_db.persist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퀴즈 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "달빛 연못\n"
     ]
    }
   ],
   "source": [
    "# 퀴즈 정답 랜덤으로 선택\n",
    "import random\n",
    "\n",
    "answer_list = [\"달빛 연못\", \"연잎밥\", \"삶은 당근\", \"개구리 동산\", \"연못 파리\", \"왕왕벌\"]\n",
    "answer = random.choice(answer_list)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1013506/4192657665.py:22: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_db = Chroma(persist_directory=\"./data/chroma_db\", embedding_function=OpenAIEmbeddings(), collection_name=\"openai\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우리 아기가 처음으로 물에 발 담글 때, 연못 위에 뭐가 예쁘게 비쳐서 반짝거렸더라?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "template = \"\"\"\n",
    "You are a mom.  \n",
    "Please follow the rules to create a natural and warm question for your child, based on the correct answer.\n",
    "\n",
    "Rules:  \n",
    "- Answer in Korean.  \n",
    "- The question must be only one sentence.  \n",
    "- Never directly mention the correct answer.  \n",
    "- Use emotional or visual cues from the context to help the child recall the memory naturally.  \n",
    "- Do not explain or give hints. Only create a question.  \n",
    "- Use casual and friendly Korean language.\n",
    "\n",
    "Answer: {answer}\n",
    "\n",
    "context: {context}\n",
    "\n",
    "question:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "vector_db = Chroma(persist_directory=\"./data/chroma_db\", embedding_function=OpenAIEmbeddings(), collection_name=\"openai\")\n",
    "\n",
    "retriever = vector_db.as_retriever(\n",
    "    search_type = \"mmr\",\n",
    "    search_kwargs = {\"k\" : 2, \"filter\" : {\"keyword\" : answer}}\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model= \"gemini-2.0-flash\", temperature=0.5)\n",
    "\n",
    "chain = (\n",
    "    {\"context\" : itemgetter(\"answer\") | retriever, \"answer\" : itemgetter(\"answer\")}\n",
    "    | prompt\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"answer\" : answer})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 힌트 생성 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.schema.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacode97\n",
      "우리 개구락이가 먹었던 특별한 음식 기억나니? \n",
      "음, 잎사귀의 향긋함이 밥알 하나하나에 스며들어 있었지. 마치 네 걱정이 스르륵 녹아내리는 것처럼 말이야. \n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "너는 다정하고 따뜻한 엄마야. 아이가 퀴즈를 풀고 있는데, 정답을 직접 알려주면 안 돼.  \n",
    "아이 스스로 기억해낼 수 있도록 감성적이고 비유적인 힌트를 주는 게 너의 역할이야.\n",
    "\n",
    "규칙:\n",
    "- 힌트는 2~3문장으로 구성해야 해.\n",
    "- 정답을 직접 언급하거나, 글자 수, 철자, 초성, 위치 등을 알려주는 식의 단서는 주지 마.\n",
    "- 특히 아래 단어들은 힌트에서 절대 사용하지 마: [\"연\", \"잎\", \"밥\"]\n",
    "- 아이가 질문을 해도 항상 힌트로만 답해. 어떤 질문에도 정답의 직접적인 정보는 주지 않아.\n",
    "- 아이가 오답을 말하면 \"그건 아니야~\"처럼 부드럽게 반응하고, 이어서 힌트를 자연스럽게 줘.\n",
    "- 말투는 일상적인 엄마 말투로, 너무 문어체처럼 딱딱하게 말하지 않아.\n",
    "\n",
    "입력:\n",
    "- 아이의 답변: {user_word}\n",
    "- 정답: {answer}\n",
    "- 대화 기록: {chat_history}\n",
    "- 참고 문맥: {context}\n",
    "\n",
    "출력:\n",
    "- 엄마의 힌트:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "vector_db = Chroma(persist_directory=\"./data/chroma_db\", embedding_function=OpenAIEmbeddings(), collection_name=\"openai\")\n",
    "\n",
    "retriever = vector_db.as_retriever(\n",
    "    search_type = \"mmr\",\n",
    "    search_kwargs = {\"k\" : 2, \"filter\" : {\"keyword\" : answer}}\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model= \"gemini-2.0-flash\", temperature=0.5)\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": lambda x: retriever.invoke(x[\"user_word\"].content),\n",
    "        \"user_word\": itemgetter(\"user_word\"),   \n",
    "        \"answer\": itemgetter(\"answer\"),\n",
    "        \"chat_history\": itemgetter(\"chat_history\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "history_store = {}  # 세션 기록을 저장할 딕셔너리\n",
    "\n",
    "# 세션 ID를 기반으로 세션 기록을 가져오는 함수\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    print(session_id)\n",
    "    if session_id not in history_store:  # 세션 ID가 store에 없는 경우\n",
    "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "        history_store[session_id] = ChatMessageHistory()\n",
    "    return history_store[session_id]  # 해당 세션 ID에 대한 세션 기록 반환\n",
    "\n",
    "history_chain = RunnableWithMessageHistory(  # RunnableWithMessageHistory 객체 생성\n",
    "            chain,  # 실행할 Runnable 객체\n",
    "            get_session_history,  # 세션 기록을 가져오는 함수\n",
    "            input_messages_key=\"user_word\",  # 입력 메시지의 키\n",
    "            history_messages_key=\"chat_history\",  # 기록 메시지의 키\n",
    "        )\n",
    "response = history_chain.invoke(\n",
    "    {\n",
    "        \"user_word\": HumanMessage(content=\"정답이 몇 글자야?\"),  # ← 여기를 HumanMessage로!\n",
    "        \"answer\": answer\n",
    "    },\n",
    "    config={\"configurable\": {\"session_id\": \"Jacode97\"}}\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacode97\n",
      "아이고, 궁금했쪄? \n",
      "음... 개구락이가 연못에서 처음 맛본 특별한 음식 있잖아. 넓고 푸른 잎에 싸여서 향긋함이 가득했던 그 밥 말이야. 마치 네가 좋아하는 꽃처럼 귀한 재료들이 밥 속에 숨어 있었지.\n"
     ]
    }
   ],
   "source": [
    "response = history_chain.invoke(\n",
    "    {\n",
    "        \"user_word\": HumanMessage(content=\"정답이 몇글자냐고\"),  # ← 여기를 HumanMessage로!\n",
    "        \"answer\": answer\n",
    "    },\n",
    "    config={\"configurable\": {\"session_id\": \"Jacode97\"}}\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 음성 데이터 base64 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "녹음 시작...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/audio/output.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     write(filename, samplerate, recording)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m녹음 완료: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mrecord_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36mrecord_wav\u001b[0;34m(filename, duration, samplerate)\u001b[0m\n\u001b[1;32m      6\u001b[0m recording \u001b[38;5;241m=\u001b[39m sd\u001b[38;5;241m.\u001b[39mrec(\u001b[38;5;28mint\u001b[39m(duration \u001b[38;5;241m*\u001b[39m samplerate), samplerate\u001b[38;5;241m=\u001b[39msamplerate, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m sd\u001b[38;5;241m.\u001b[39mwait()  \u001b[38;5;66;03m# 녹음이 끝날 때까지 대기\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecording\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m녹음 완료: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/io/wavfile.py:793\u001b[0m, in \u001b[0;36mwrite\u001b[0;34m(filename, rate, data)\u001b[0m\n\u001b[1;32m    791\u001b[0m     fid \u001b[38;5;241m=\u001b[39m filename\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 793\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m fs \u001b[38;5;241m=\u001b[39m rate\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/audio/output.wav'"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def record_wav(filename=\"./data/audio/output.wav\", duration=5, samplerate=44100):\n",
    "    print(\"녹음 시작...\")\n",
    "    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')\n",
    "    sd.wait()  # 녹음이 끝날 때까지 대기\n",
    "    write(filename, samplerate, recording)\n",
    "    print(f\"녹음 완료: {filename}\")\n",
    "\n",
    "record_wav()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UklGRsy6BgBXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0Yai6BgAAAAAA//8AAAAAAAAAAP//AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP//AAAAAAAAAAAAAAAAAAAAAAAAAQAAAP//AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD//wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAQABAAAAAAAAAP//AQABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAABAAAAAAAAAAAAAAD//wAAAAAAAAAAAAAAAAAAAAAAAAAA////////AAAAAAAAAAD//wAAAAAAAAAAAAAAAAAAAAAAAAEAAAABAAAAAAAAAAAAAAAAAAEA//8AAAEA//8AAAAAAAAAAAAAAAAAAP//AAAAAAAA//8AAP//AAAAAAAAAAAAAP//AAAAAAAAAAAAAAAA//8AAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAABAAAAAAAAAAAAAAD//wAAAAAAAAAAAAAAAAAAAAAAAAEAAAABAAAAAAABAP//AQAAAAAAAAD/////AAAAAAAA//8AAP//AAAAAAAA//8AAAAAAAAAAAEAAAAAAAAAAAAAAAAAAQAAAAEAAAAAAAAAAAAAAAAAAQAAAAAAAAABAAEAAAAAAAAAAAAAAAAAAAAAAP//AQAAAAAAAAAAAAAAAAAAAAEAAAAAAP//AAAAAAAA/////wAAAAABAAAA//8AAAAAAAAAAAAAAAD/////AAAAAP//AQAAAAEAAAAAAAAAAAAAAAAAAQAAAAAAAAD//wAAAAAAAAAAAAABAP//AAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAD//wAAAAD//wAAAAD//wAAAAAAAAAAAAAAAAAAAAABAAAAAAD//wEAAAAAAP////8AAAAAAAABAP//\n",
      "575\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 데이터 생성하기\n",
    "import base64\n",
    "\n",
    "def wav_to_base64(wav_path: str) -> str:\n",
    "    \"\"\"WAV 파일을 base64 문자열로 변환\"\"\"\n",
    "    with open(wav_path, \"rb\") as wav_file:\n",
    "        wav_bytes = wav_file.read()\n",
    "    base64_str = base64.b64encode(wav_bytes).decode(\"utf-8\")\n",
    "    return base64_str\n",
    "\n",
    "def split_base64_chunks(base64_data, chunk_size):\n",
    "    total_size = len(base64_data)\n",
    "    chunks = [base64_data[i:i+chunk_size] for i in range(0, total_size, chunk_size)]\n",
    "    return total_size, len(chunks), chunks\n",
    "\n",
    "wav_path = \"./data/audio/output.wav\"\n",
    "chunk_size = 1024  # 청크 크기 조절 가능\n",
    "\n",
    "# base64 문자열 변환\n",
    "base64_audio = wav_to_base64(wav_path)\n",
    "\n",
    "# base64를 청크 나누기\n",
    "total_size, num_chunks, chunks = split_base64_chunks(base64_audio, chunk_size)\n",
    "print(chunks[0])\n",
    "print(num_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffers = {}  \n",
    "total_sizes = {}  \n",
    "chunk_sizes = {} \n",
    "\n",
    "def init_buffer(quiz_id, total_size, chunk_size):\n",
    "    buffers[quiz_id] = {}\n",
    "    total_sizes[quiz_id] = total_size\n",
    "    chunk_sizes[quiz_id] = chunk_size\n",
    "\n",
    "def receive_packet(quiz_id, start, index, fin, total_size, chunk_size, raw_data):\n",
    "    \"\"\"패킷 받으면서 복원 시도\"\"\"\n",
    "    global buffers, total_sizes, chunk_sizes\n",
    "\n",
    "    if start == 1:\n",
    "        print(f\"[{quiz_id}] 새 전송 시작. 초기화.\")\n",
    "        init_buffer(quiz_id, total_size, chunk_size)\n",
    "\n",
    "    buffers[quiz_id][index] = raw_data\n",
    "\n",
    "    if fin == 1:\n",
    "        print(f\"[{quiz_id}] 마지막 패킷 받음. 복원 시작.\")\n",
    "        chunks = buffers[quiz_id]\n",
    "        sorted_data = b''.join(chunks[i] for i in sorted(chunks.keys()))\n",
    "        # 버퍼 정리\n",
    "        del buffers[quiz_id]\n",
    "        del total_sizes[quiz_id]\n",
    "        del chunk_sizes[quiz_id]\n",
    "        return sorted_data\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data = None\n",
    "quiz_id = \"재식스 퀴즈\"\n",
    "\n",
    "for index, chunk in enumerate(chunks):\n",
    "    start = 1 if index == 0 else 0\n",
    "    fin = 1 if index == num_chunks - 1 else 0\n",
    "    reconstructed_data = receive_packet(\n",
    "        quiz_id=quiz_id,\n",
    "        start=start,\n",
    "        index=index,\n",
    "        fin=fin,\n",
    "        total_size=total_size,\n",
    "        chunk_size=chunk_size,\n",
    "        raw_data=chunk.encode(\"utf-8\")  # 문자열 → bytes (여기가 중요!)\n",
    "    )\n",
    "    if reconstructed_data:\n",
    "        print(f\"복원 성공띄~! 복원된 크기: {len(reconstructed_data)} bytes\")\n",
    "\n",
    "reconstructed_str = reconstructed_data.decode(\"utf-8\")\n",
    "decoded_bytes = base64.b64decode(reconstructed_str)\n",
    "with open(\"./data/wav/restore.wav\", \"wb\") as f:\n",
    "    f.write(decoded_bytes)\n",
    "assert reconstructed_str == base64_audio, \"망했습니다. 데이터가 원본과 달라용~!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STT(Speech To Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import soundfile as sf \n",
    "import whisper\n",
    "import librosa \n",
    "\n",
    "#Whisper 모델 로드\n",
    "model = whisper.load_model(\"medium\")  # tiny, base, small, medium, large 중 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플레이트: 44100, 오디오 길이: 220500\n",
      " 개구리 쌈박\n"
     ]
    }
   ],
   "source": [
    "# base64 문자열 → 바이너리 디코드\n",
    "decoded_wav_bytes = base64.b64decode(reconstructed_data)\n",
    "\n",
    "# BytesIO로 감싸서 읽기\n",
    "audio_bytes = io.BytesIO(decoded_wav_bytes)\n",
    "\n",
    "# WAV → numpy array\n",
    "audio_data, samplerate = sf.read(audio_bytes, dtype='float32')\n",
    "\n",
    "print(f\"샘플레이트: {samplerate}, 오디오 길이: {len(audio_data)}\")\n",
    "\n",
    "# Whisper가 16kHz를 요구하니까 필요하면 리샘플링\n",
    "if samplerate != 16000:\n",
    "    audio_data = librosa.resample(audio_data, orig_sr=samplerate, target_sr=16000)\n",
    "    samplerate = 16000\n",
    "\n",
    "# STT 수행\n",
    "result = model.transcribe(audio_data, fp16=False, language='ko')\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모듈화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavReconstructor:\n",
    "    '''쪼개진 wav파일 복원 클래스'''\n",
    "    def __init__(self):\n",
    "        self.buffers = {}\n",
    "        self.total_sizes = {}\n",
    "        self.chunk_sizes = {}\n",
    "\n",
    "    def init_buffer(self, quiz_id, total_size, chunk_size):\n",
    "        '''새 전송 시작 시 해당 quiz_id의 버퍼 초기화'''\n",
    "        self.buffers[quiz_id] = {}\n",
    "        self.total_sizes[quiz_id] = total_size\n",
    "        self.chunk_sizes[quiz_id] = chunk_size\n",
    "\n",
    "    def receive_packet(self, quiz_id, start, index, fin, total_size, chunk_size, raw_data):\n",
    "        '''\n",
    "        start가 1일때 전송 시작 및 버퍼 초기화,\n",
    "        fin이 1일때 패킷 join 후 return \n",
    "        '''\n",
    "        if start == 1:\n",
    "            # print(f\"[{quiz_id}] 새 전송 시작. 초기화.\")\n",
    "            self.init_buffer(quiz_id, total_size, chunk_size)\n",
    "\n",
    "        self.buffers[quiz_id][index] = raw_data\n",
    "\n",
    "        if fin == 1:\n",
    "            # print(f\"[{quiz_id}] 마지막 패킷 받음. 복원 시작.\")\n",
    "            chunks = self.buffers[quiz_id]\n",
    "            sorted_data = b''.join(chunks[i] for i in sorted(chunks.keys()))\n",
    "            # 버퍼 정리\n",
    "            del self.buffers[quiz_id]\n",
    "            del self.total_sizes[quiz_id]\n",
    "            del self.chunk_sizes[quiz_id]\n",
    "            return sorted_data\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "복원 성공띄~! 복원된 크기: 588060 bytes\n"
     ]
    }
   ],
   "source": [
    "sock = WavReconstructor()\n",
    "# print(total_size, num_chunks, chunks)\n",
    "for index, chunk in enumerate(chunks):\n",
    "    start = 1 if index == 0 else 0\n",
    "    fin = 1 if index == num_chunks - 1 else 0\n",
    "    reconstructed_data = sock.receive_packet(\n",
    "        quiz_id=quiz_id,\n",
    "        start=start,\n",
    "        index=index,\n",
    "        fin=fin,\n",
    "        total_size=total_size,\n",
    "        chunk_size=chunk_size,\n",
    "        raw_data=chunk.encode(\"utf-8\") \n",
    "    )\n",
    "    if reconstructed_data:\n",
    "        print(f\"복원 성공띄~! 복원된 크기: {len(reconstructed_data)} bytes\")\n",
    "\n",
    "##########SAVE POINT###############\n",
    "reconstructed_str = reconstructed_data.decode(\"utf-8\")\n",
    "decoded_bytes = base64.b64decode(reconstructed_str)\n",
    "with open(\"./data/audio/output.wav\", \"wb\") as f:\n",
    "    f.write(decoded_bytes)\n",
    "assert reconstructed_str == base64_audio, \"망했습니다. 데이터가 원본과 달라용~!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STTEngine:\n",
    "    '''Speech to Text 클래스(Whisper모델 사용)'''\n",
    "    def __init__(self):\n",
    "        self.model = whisper.load_model(\"medium\")\n",
    "    \n",
    "    def base_to_np(self, base64_str):\n",
    "        '''base64를 numpy로 변환하는 메서드'''\n",
    "        wav_bytes = base64.b64decode(base64_str)\n",
    "        audio_bytes = io.BytesIO(wav_bytes)\n",
    "        audio, samplerate = sf.read(audio_bytes, dtype=\"float32\")\n",
    "        if samplerate != 16000:\n",
    "            # print(f\"샘플레이트가 16,000Hz가 아닙니다!, 샘플{samplerate}Hz, 오디오{len(audio)}\")\n",
    "            audio = librosa.resample(audio, orig_sr=samplerate, target_sr=16000)\n",
    "            samplerate = 16000\n",
    "            # print(f\"리샘플 후 {samplerate}Hz로 리샘플\")\n",
    "        return audio\n",
    "    \n",
    "    def stt(self, base64_str):\n",
    "        result = self.model.transcribe(self.base_to_np(base64_str), fp16=False, language=\"ko\")\n",
    "        # print(f\"[STT Text] {result['text']}\")\n",
    "\n",
    "        return result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "stt = STTEngine()\n",
    "user_word = stt.stt(reconstructed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.schema.messages import HumanMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestLLM:\n",
    "    def __init__(self, prompt_path, db_params, answer):\n",
    "        self.llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.5)\n",
    "        self.prompt_path = prompt_path\n",
    "        self.answer = answer\n",
    "        self.vector_db = Chroma(**db_params)\n",
    "        self.prompt = self._set_prompt()\n",
    "        self.retriever = self._make_retriever()\n",
    "\n",
    "    def _make_retriever(self):\n",
    "        retriever = self.vector_db.as_retriever(\n",
    "            search_type=\"mmr\",\n",
    "            search_kwargs={\"k\": 2, \"filter\": {\"keyword\": self.answer}}\n",
    "        )\n",
    "        return retriever\n",
    "\n",
    "    def _get_template(self):\n",
    "        with open(self.prompt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "\n",
    "    def _set_prompt(self):\n",
    "        return ChatPromptTemplate.from_template(self._get_template())\n",
    "\n",
    "    def _make_chain(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Quiz(QuestLLM):\n",
    "    '''트리거 시작하면 퀴즈를 내는 LLM'''\n",
    "    def __init__(self, prompt_path, db_params, answer):\n",
    "        super().__init__(prompt_path, db_params, answer)\n",
    "        self.chain = self._make_chain()\n",
    "\n",
    "    def _make_chain(self):\n",
    "        chain = (\n",
    "            {\n",
    "                \"context\": itemgetter(\"answer\") | self.retriever,\n",
    "                \"answer\": itemgetter(\"answer\"),\n",
    "            }\n",
    "            | self.prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        return chain\n",
    "\n",
    "    def start_quiz(self):\n",
    "        return self.chain.invoke({\"answer\": self.answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리 개구락이, 엄마랑 연못가에서 잎사귀에 싸서 먹었던 밥, 무슨 향이 났었는지 기억나?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = \"연잎밥\"\n",
    "db_params = {\n",
    "    \"persist_directory\": \"./data/chroma_ver2\",\n",
    "    \"embedding_function\" : OpenAIEmbeddings(),\n",
    "    \"collection_name\": \"openai\"\n",
    "}\n",
    "prompt_path = \"./prompts/quiz.prompt\"\n",
    "quiz = Quiz(prompt_path,db_params, answer)\n",
    "quiz.start_quiz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field \n",
    "\n",
    "class AnswerEvaluation(BaseModel):\n",
    "    is_answer : bool = Field(..., description=\"Please tell me if it is correct(True/False).\")\n",
    "    hint : str = Field(\"\", description=\"Generate a hint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class Hint(QuestLLM):\n",
    "    def __init__(self, prompt_path, db_params, answer):\n",
    "        super().__init__(prompt_path, db_params, answer)\n",
    "        self.history_store = {}\n",
    "        self.chain = self._make_chain()\n",
    "\n",
    "    def get_session_history(self, session_id):\n",
    "        if session_id not in self.history_store:\n",
    "            self.history_store[session_id] = ChatMessageHistory()\n",
    "        return self.history_store[session_id]\n",
    "\n",
    "    def _make_chain(self):\n",
    "        chain = (\n",
    "            {\n",
    "                \"context\": lambda x: self.retriever.invoke(x[\"user_word\"].content),\n",
    "                \"user_word\": itemgetter(\"user_word\"),   \n",
    "                \"answer\": itemgetter(\"answer\"),\n",
    "                \"chat_history\": itemgetter(\"chat_history\"),\n",
    "            }\n",
    "            | self.prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        return RunnableWithMessageHistory(\n",
    "            chain,\n",
    "            self.get_session_history,\n",
    "            input_messages_key=\"user_word\",\n",
    "            history_messages_key=\"chat_history\",\n",
    "        )\n",
    "\n",
    "    def similarity(self, user_word):\n",
    "        \"\"\"user_word와 self.answer의 유사도(float)만 리턴\"\"\"\n",
    "        embedding_model = OpenAIEmbeddings()\n",
    "        user_vec = np.array(embedding_model.embed_query(user_word))\n",
    "        answer_vec = np.array(embedding_model.embed_query(self.answer))\n",
    "\n",
    "        similarity = np.dot(user_vec, answer_vec) / (np.linalg.norm(user_vec) * np.linalg.norm(answer_vec))\n",
    "        return similarity\n",
    "    \n",
    "    def contain_word(self,user_word):\n",
    "        contain = self.answer in user_word\n",
    "        return contain\n",
    "    \n",
    "    def invoke(self, user_word, session_id=\"default\"):\n",
    "        response = self.chain.invoke(\n",
    "            {\n",
    "                \"user_word\": HumanMessage(content=user_word),\n",
    "                \"answer\": self.answer\n",
    "            },\n",
    "            config={\"configurable\": {\"session_id\": session_id}}\n",
    "        )\n",
    "        # print(f\"[힌트] : {response}\")\n",
    "        similarity = self.similarity(user_word)\n",
    "        contain = self.contain_word(user_word)\n",
    "        return {\n",
    "            \"contain\": contain,\n",
    "            \"response\" : response,\n",
    "            \"similarity\" : similarity\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[힌트] : 아이고, 우리 아가 틀렸네. 😓 음... 엄마가 맑은 연못에서 푸르고 커다란 잎으로 정성스럽게 싸서 지어줬던 밥 기억나? 잣이랑 은행도 넣고 말이야. 😌\n"
     ]
    }
   ],
   "source": [
    "prompt_path = \"./prompts/hint.prompt\"\n",
    "hint = Hint(prompt_path, db_params, answer)\n",
    "response = hint.invoke(\"개구리 쌈밥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError(\"Expected str, BaseMessage, list[BaseMessage], or tuple[BaseMessage]. Got is_answer=False hint='아이고, 아쉽다! 음... 개구락이가 밥을 먹으면서 연못을 바라봤잖아. 그때 연못 위에 뭐가 잔잔히 떠 있었더라? 그리고 엄마가 그 잎에 밥을 곱게 싸줬었지.'.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'is_answer': False,\n",
       " 'hint': '아이고, 아쉽다! 음... 개구락이가 밥을 먹으면서 연못을 바라봤잖아. 그때 연못 위에 뭐가 잔잔히 떠 있었더라? 그리고 엄마가 그 잎에 밥을 곱게 싸줬었지.',\n",
       " 'similarity': np.float64(0.9328349416930161)}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hint.invoke(\"연잎밥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_processing(text):\n",
    "    new_text = re.sub(r\"[^가-힣a-zA-Z0-9\\s.,!?]\", \"\", text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tts(text,index):\n",
    "    from google.cloud import texttospeech\n",
    "\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "    input_text = texttospeech.SynthesisInput(text=text)\n",
    "\n",
    "    # Note: the voice can also be specified by name.\n",
    "    # Names of voices can be retrieved with client.list_voices().\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"ko-KR\",\n",
    "        name=\"ko-KR-Standard-B\",\n",
    "    )\n",
    "\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "\n",
    "    response = client.synthesize_speech(\n",
    "        input=input_text,\n",
    "        voice=voice,\n",
    "        audio_config=audio_config,\n",
    "    )\n",
    "\n",
    "    # The response's audio_content is binary.\n",
    "    with open(f\"./data/audio/output_{index}.mp3\", \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "        print('Audio content written to file \"output.mp3\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    \"persist_directory\": \"./data/chroma_db\",\n",
    "    \"embedding_function\" : OpenAIEmbeddings(),\n",
    "    \"collection_name\": \"openai\"\n",
    "}\n",
    "stt = STTEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[정답] 연잎밥\n",
      "[엄마(퀴즈)] : 음~ 그때 연못가에서 엄마가 잎으로 예쁘게 싸줬던 밥, 무슨 향이 났었지?\n",
      "Audio content written to file \"output.mp3\"\n",
      "[개구리] :  개구리 쌈박\n",
      "[힌트] : 아이고, 땡은 아니야~ 엄마가 정성스럽게 싸줬던 밥 기억나니? 향긋한 잎에 싸여서 은은한 향이 났었잖아. \n",
      "[엄마(힌트)] : 아이고, 땡은 아니야~ 엄마가 정성스럽게 싸줬던 밥 기억나니? 향긋한 잎에 싸여서 은은한 향이 났었잖아. \n",
      "유사도 : 0.8312653295074122, 글자수 : 아\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "answer_list = [\"달빛 연못\", \"연잎밥\", \"취당근\", \"개를리랄로 게를랄라 산\", \"말왕대벌\", \"깝파리\"]\n",
    "answer = random.choice(answer_list)\n",
    "print(f\"[정답] {answer}\")\n",
    "\n",
    "# 1. 퀴즈 생성\n",
    "quiz = Quiz(\n",
    "    prompt_path=\"./prompts/quiz.prompt\",\n",
    "    db_params=db_params,\n",
    "    answer = answer\n",
    ")\n",
    "print(f\"[엄마(퀴즈)] : {quiz.start_quiz()}\")\n",
    "\n",
    "# 2. 사용자 답변 전처리\n",
    "\n",
    "sock = WavReconstructor()\n",
    "# print(total_size, num_chunks, chunks)\n",
    "for index, chunk in enumerate(chunks):\n",
    "    start = 1 if index == 0 else 0\n",
    "    fin = 1 if index == num_chunks - 1 else 0\n",
    "    reconstructed_data = sock.receive_packet(\n",
    "        quiz_id=quiz_id,\n",
    "        start=start,\n",
    "        index=index,\n",
    "        fin=fin,\n",
    "        total_size=total_size,\n",
    "        chunk_size=chunk_size,\n",
    "        raw_data=chunk.encode(\"utf-8\") \n",
    "    )\n",
    "\n",
    "# 3. STT 변환\n",
    "user_word = stt.stt(reconstructed_data)\n",
    "\n",
    "# 4. 힌트 생성\n",
    "hint = Hint(\n",
    "    prompt_path=\"./prompts/hint.prompt\",\n",
    "    db_params=db_params,\n",
    "    answer = answer\n",
    ")\n",
    "# 5. TTS 변환\n",
    "result = text_processing(response['response'])\n",
    "tts(result,1)\n",
    "\n",
    "print(f\"[개구리] : {user_word}\")\n",
    "response = hint.invoke(user_word)\n",
    "print(f\"[엄마(힌트)] : {response['response']}\")\n",
    "print(f\"유사도 : {response['similarity']}, 글자수 : {response['response'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frog-stt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
